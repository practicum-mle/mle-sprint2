### **Этап 5. Подбор гиперпараметров и обучение новой версии модели**

На заключительном этапе проекта вы сосредоточитесь на оптимизации гиперпараметров модели. Вы будете использовать минимум два метода, один из которых вы реализуете с помощью библиотеки `optuna`. Для этого: 

1. Подберите гиперпараметры, используя ****`optuna`. Залогируйте процесс их оптимизации, их значения и метрики качества с помощью MLflow Callback.
2. Примените второй метод оптимизации. Это может быть ещё один алгоритм из библиотеки `optuna` или Random Search, Grid Search, `HalvingGridSearchCV` из `sklearn`. Попутно логируйте процесс и результаты в MLflow. 
3. Обучите новую версию модели, используя отобранные признаки и лучшие гиперпараметры. Оцените её производительность на тестовой выборке и сравните с предыдущими версиями моделей.
4. Финальную модель, её метрики и дополнительные артефакты также залогируете в MLflow, а модель зарегистрируйте в MLflow Model Registry с новой версией. Укажите применённые методы оптимизации гиперпараметров и достигнутые улучшения.

**Результаты этапа:**

1. Код для подбора гиперпараметров и обучения модели, оформленный и сохраненный на GitHub. Не забудьте про подробные комментарии к каждому этапу работы.
2. Запуски в MLflow: Убедитесь, что весь процесс подбора гиперпараметров, включая эксперименты с разными методами и их результаты, окружение, а также финальные метрики новой версии модели, залогированы в MLflow.
3. Финальная версия модели в MLflow Model Registry.